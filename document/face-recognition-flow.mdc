# ì–¼êµ´ ì¸ì¦ ë¡œì§ êµ¬í˜„ ê°€ì´ë“œ

## ì „ì²´ í”Œë¡œìš°

```
1. webOS Client (Flutter)
   â†“ ì¹´ë©”ë¼ë¡œ ì–¼êµ´ ì‚¬ì§„ ì´¬ì˜
   â†“ JPEG ì´ë¯¸ì§€ë¥¼ Base64 ë˜ëŠ” Multipartë¡œ ì¸ì½”ë”©

2. HTTP POST â†’ Express Backend
   â†“ /auth/face-login

3. Backend (Node.js)
   â†“ ì´ë¯¸ì§€ ìˆ˜ì‹  â†’ Face Recognition Library
   â†“ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ (face encoding)
   â†“ DBì˜ ì €ì¥ëœ ì–¼êµ´ë“¤ê³¼ ë¹„êµ

4. ì¸ì¦ ì„±ê³µ ì‹œ
   â†“ JWT í† í° ë°œê¸‰
   â†“ ì‚¬ìš©ì ì •ë³´ ë°˜í™˜

5. webOS Client
   â†“ í† í° ì €ì¥ (SharedPreferences)
   â†“ í™ˆ í™”ë©´ìœ¼ë¡œ ì´ë™
```

---

## 1. webOS Client (Flutter) êµ¬í˜„

### 1-1. ì¹´ë©”ë¼ ì„œë¹„ìŠ¤ (camera_service.dart)

```dart
import 'package:webos_service_helper/utils.dart';

class CameraService {
  // 1. AI ëª¨ë¸ ì„¤ì¹˜
  static Future<void> installModel() async {
    await callOneReply(
      uri: 'luna://com.webos.service.aiinferencemanager',
      method: 'installModel',
      payload: {'id': 'FACE'},
    );
  }

  // 2. ì¹´ë©”ë¼ ëª©ë¡ ì¡°íšŒ
  static Future<String?> getCameraId() async {
    final res = await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'getCameraList',
      payload: {},
    );
    return res?['deviceList']?[0]?['id'];
  }

  // 3. ì¹´ë©”ë¼ ê¶Œí•œ ì„¤ì •
  static Future<void> setPermission() async {
    await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'setPermission',
      payload: {'appId': 'com.webos.app.homescreen'},
    );
  }

  // 4. ì¹´ë©”ë¼ ì—´ê¸°
  static Future<int?> openCamera(String cameraId) async {
    final res = await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'open',
      payload: {
        'appId': 'com.webos.app.homescreen',
        'id': cameraId,
        'mode': 'primary',
      },
    );
    return res?['handle'];
  }

  // 5. í¬ë§· ì„¤ì • (1280x720 JPEG)
  static Future<void> setFormat(int handle) async {
    await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'setFormat',
      payload: {
        'handle': handle,
        'params': {
          'format': 'JPEG',
          'fps': 30,
          'width': 1280,
          'height': 720,
        },
      },
    );
  }

  // 6. í”„ë¦¬ë·° ì‹œì‘
  static Future<void> startPreview(int handle) async {
    await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'startPreview',
      payload: {'handle': handle},
    );
  }

  // 7. ì‚¬ì§„ ì´¬ì˜ (ìº¡ì²˜)
  static Future<String?> takePicture(int handle) async {
    final res = await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'takePicture',
      payload: {
        'handle': handle,
        'params': {
          'width': 640,
          'height': 480,
          'format': 'JPEG',
        },
      },
    );
    // ë°˜í™˜ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” Base64 ë°ì´í„°
    return res?['imagePath'] ?? res?['imageData'];
  }

  // 8. ì¹´ë©”ë¼ ë‹«ê¸°
  static Future<void> closeCamera(int handle) async {
    await callOneReply(
      uri: 'luna://com.webos.service.camera2',
      method: 'close',
      payload: {'handle': handle},
    );
  }
}
```

### 1-2. ì–¼êµ´ ì¸ì¦ í™”ë©´ (face_login_page.dart)

```dart
import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'dart:io';

class FaceLoginPage extends StatefulWidget {
  @override
  _FaceLoginPageState createState() => _FaceLoginPageState();
}

class _FaceLoginPageState extends State<FaceLoginPage> {
  bool _isLoading = false;
  String? _message;
  int? _cameraHandle;

  @override
  void initState() {
    super.initState();
    _initializeCamera();
  }

  // ì¹´ë©”ë¼ ì´ˆê¸°í™”
  Future<void> _initializeCamera() async {
    try {
      await CameraService.installModel();
      final cameraId = await CameraService.getCameraId();
      if (cameraId == null) {
        setState(() => _message = 'ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        return;
      }

      await CameraService.setPermission();
      _cameraHandle = await CameraService.openCamera(cameraId);
      if (_cameraHandle != null) {
        await CameraService.setFormat(_cameraHandle!);
        await CameraService.startPreview(_cameraHandle!);
        setState(() => _message = 'ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ');
      }
    } catch (e) {
      setState(() => _message = 'ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
    }
  }

  // ì–¼êµ´ ì¸ì¦ ì‹¤í–‰
  Future<void> _performFaceLogin() async {
    if (_cameraHandle == null) {
      setState(() => _message = 'ì¹´ë©”ë¼ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
      return;
    }

    setState(() {
      _isLoading = true;
      _message = 'ì–¼êµ´ ì¸ì‹ ì¤‘...';
    });

    try {
      // 1. ì‚¬ì§„ ì´¬ì˜
      final imagePath = await CameraService.takePicture(_cameraHandle!);
      if (imagePath == null) {
        throw Exception('ì‚¬ì§„ ì´¬ì˜ ì‹¤íŒ¨');
      }

      // 2. ë°±ì—”ë“œë¡œ ì „ì†¡
      final response = await _sendToBackend(imagePath);

      if (response['success']) {
        // 3. í† í° ì €ì¥
        final token = response['token'];
        await _saveToken(token);

        // 4. í™ˆ í™”ë©´ìœ¼ë¡œ ì´ë™
        Navigator.pushReplacementNamed(context, '/home');
      } else {
        setState(() => _message = 'ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: ${response['message']}');
      }
    } catch (e) {
      setState(() => _message = 'ì˜¤ë¥˜ ë°œìƒ: $e');
    } finally {
      setState(() => _isLoading = false);
    }
  }

  // ë°±ì—”ë“œë¡œ ì´ë¯¸ì§€ ì „ì†¡
  Future<Map<String, dynamic>> _sendToBackend(String imagePath) async {
    final uri = Uri.parse('http://localhost:8080/auth/face-login');
    final request = http.MultipartRequest('POST', uri);

    // ì´ë¯¸ì§€ íŒŒì¼ ì²¨ë¶€
    request.files.add(await http.MultipartFile.fromPath('image', imagePath));

    final response = await request.send();
    final responseBody = await response.stream.bytesToString();

    if (response.statusCode == 200) {
      return json.decode(responseBody);
    } else {
      throw Exception('ì„œë²„ ì˜¤ë¥˜: ${response.statusCode}');
    }
  }

  // í† í° ì €ì¥ (SharedPreferences)
  Future<void> _saveToken(String token) async {
    // TODO: SharedPreferencesì— ì €ì¥
    // final prefs = await SharedPreferences.getInstance();
    // await prefs.setString('auth_token', token);
  }

  @override
  void dispose() {
    if (_cameraHandle != null) {
      CameraService.closeCamera(_cameraHandle!);
    }
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('ì–¼êµ´ ì¸ì¦ ë¡œê·¸ì¸')),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Icon(Icons.face, size: 100, color: Colors.blue),
            SizedBox(height: 20),
            Text(_message ?? 'ì¹´ë©”ë¼ë¥¼ ì´ˆê¸°í™” ì¤‘...'),
            SizedBox(height: 40),
            _isLoading
                ? CircularProgressIndicator()
                : ElevatedButton.icon(
                    onPressed: _performFaceLogin,
                    icon: Icon(Icons.camera_alt),
                    label: Text('ì–¼êµ´ ì¸ì¦ ì‹œì‘'),
                  ),
          ],
        ),
      ),
    );
  }
}
```

---

## 2. Backend (Express + TypeScript) êµ¬í˜„

### 2-1. Face Recognition ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
cd /Users/Inyoung/Desktop/26-2/lg-capstone/2025_sogang_6/src/backend
pnpm add face-api.js @tensorflow/tfjs-node canvas
pnpm add -D @types/canvas
```

### 2-2. Face Recognition ìœ í‹¸ë¦¬í‹° (faceRecognition.ts)

```typescript
// src/common/utils/faceRecognition.ts
import * as faceapi from "face-api.js";
import * as canvas from "canvas";
import * as tf from "@tensorflow/tfjs-node";
import path from "path";

// Canvas ì„¤ì • (face-api.jsê°€ ë¸Œë¼ìš°ì € API ëŒ€ì‹  ì‚¬ìš©)
const { Canvas, Image, ImageData } = canvas;
faceapi.env.monkeyPatch({ Canvas, Image, ImageData } as any);

// ëª¨ë¸ ë¡œë“œ ì—¬ë¶€
let modelsLoaded = false;

// Face Recognition ëª¨ë¸ ë¡œë“œ
export async function loadModels() {
  if (modelsLoaded) return;

  const modelPath = path.join(__dirname, "../../../models");

  await Promise.all([
    faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath),
    faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath),
    faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath),
  ]);

  modelsLoaded = true;
  console.log("âœ… Face recognition models loaded");
}

// ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
export async function extractFaceDescriptor(
  imageBuffer: Buffer
): Promise<Float32Array | null> {
  const img = await canvas.loadImage(imageBuffer);
  const detection = await faceapi
    .detectSingleFace(img as any)
    .withFaceLandmarks()
    .withFaceDescriptor();

  if (!detection) {
    return null; // ì–¼êµ´ ê°ì§€ ì•ˆë¨
  }

  return detection.descriptor;
}

// ë‘ ì–¼êµ´ íŠ¹ì§• ë¹„êµ (ìœ ì‚¬ë„ ê³„ì‚°)
export function compareFaces(
  descriptor1: Float32Array,
  descriptor2: Float32Array
): number {
  const distance = faceapi.euclideanDistance(descriptor1, descriptor2);
  const similarity = 1 - distance; // 0~1 (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
  return similarity;
}

// ì–¼êµ´ ë§¤ì¹­ (ì„ê³„ê°’ 0.6 ì´ìƒì´ë©´ ë™ì¼ì¸)
export function isSamePerson(
  descriptor1: Float32Array,
  descriptor2: Float32Array,
  threshold: number = 0.6
): boolean {
  const similarity = compareFaces(descriptor1, descriptor2);
  return similarity >= threshold;
}
```

### 2-3. Auth Service ì—…ë°ì´íŠ¸

```typescript
// src/api/auth/authService.ts
import { authRepository } from "./authRepository";
import jwt from "jsonwebtoken";
import { env } from "@/common/utils/envConfig";
import {
  extractFaceDescriptor,
  isSamePerson,
  loadModels,
} from "@/common/utils/faceRecognition";

export class AuthService {
  // ì–¼êµ´ ì¸ì‹ ë¡œê·¸ì¸
  async faceLogin(imageBuffer: Buffer): Promise<{
    token: string;
    userId: number;
    username: string;
  }> {
    // 1. Face Recognition ëª¨ë¸ ë¡œë“œ
    await loadModels();

    // 2. ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
    const uploadedDescriptor = await extractFaceDescriptor(imageBuffer);
    if (!uploadedDescriptor) {
      throw new Error("ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
    }

    // 3. DBì—ì„œ ëª¨ë“  ì‚¬ìš©ì ì–¼êµ´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const users = await authRepository.getAllUsers();

    // 4. ê° ì‚¬ìš©ìì™€ ë¹„êµ
    for (const user of users) {
      const storedDescriptor = new Float32Array(JSON.parse(user.face_encoding));

      if (isSamePerson(uploadedDescriptor, storedDescriptor)) {
        // 5. ë§¤ì¹­ ì„±ê³µ â†’ JWT ë°œê¸‰
        const token = jwt.sign(
          { userId: user.id, username: user.username },
          env.JWT_SECRET,
          { expiresIn: env.JWT_EXPIRES_IN }
        );

        return {
          token,
          userId: user.id,
          username: user.username,
        };
      }
    }

    throw new Error("ë“±ë¡ëœ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
  }

  // ì–¼êµ´ ë“±ë¡ (ê°œë°œìš©)
  async registerFace(
    imageBuffer: Buffer,
    username: string
  ): Promise<{ userId: number }> {
    await loadModels();

    const descriptor = await extractFaceDescriptor(imageBuffer);
    if (!descriptor) {
      throw new Error("ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
    }

    // Float32Arrayë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
    const faceEncoding = JSON.stringify(Array.from(descriptor));

    const userId = await authRepository.createUser(username, faceEncoding);

    return { userId };
  }
}

export const authService = new AuthService();
```

### 2-4. Auth Controller ì—…ë°ì´íŠ¸

```typescript
// src/api/auth/authController.ts
import { Request, Response } from "express";
import { authService } from "./authService";

export class AuthController {
  // ì–¼êµ´ì¸ì‹ ë¡œê·¸ì¸
  async faceLogin(req: Request, res: Response) {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤" });
      }

      const result = await authService.faceLogin(req.file.buffer);

      res.status(200).json({
        success: true,
        ...result,
      });
    } catch (error: any) {
      res.status(401).json({
        success: false,
        message: error.message,
      });
    }
  }

  // ì–¼êµ´ ë“±ë¡
  async registerFace(req: Request, res: Response) {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤" });
      }

      const username = req.body.username || `user_${Date.now()}`;
      const result = await authService.registerFace(req.file.buffer, username);

      res.status(201).json({
        success: true,
        ...result,
      });
    } catch (error: any) {
      res.status(400).json({
        success: false,
        message: error.message,
      });
    }
  }
}

export const authController = new AuthController();
```

### 2-5. Auth Repository ì—…ë°ì´íŠ¸

```typescript
// src/api/auth/authRepository.ts
import { db } from "@/common/utils/database";

export class AuthRepository {
  async getAllUsers(): Promise<
    Array<{ id: number; username: string; face_encoding: string }>
  > {
    const result = await db.query(
      "SELECT id, username, face_encoding FROM users"
    );
    return result.rows;
  }

  async createUser(username: string, faceEncoding: string): Promise<number> {
    const result = await db.query(
      "INSERT INTO users (username, face_encoding) VALUES ($1, $2) RETURNING id",
      [username, faceEncoding]
    );
    return result.rows[0].id;
  }
}

export const authRepository = new AuthRepository();
```

---

## 3. Face Recognition ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

ëª¨ë¸ íŒŒì¼ë“¤ì„ `src/backend/models/` í´ë”ì— ë‹¤ìš´ë¡œë“œ:

```bash
mkdir -p models
cd models

# face-api.js ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/ssd_mobilenetv1_model-weights_manifest.json
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/ssd_mobilenetv1_model-shard1
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/face_landmark_68_model-weights_manifest.json
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/face_landmark_68_model-shard1
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/face_recognition_model-weights_manifest.json
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/face_recognition_model-shard1
curl -O https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/face_recognition_model-shard2
```

---

## 4. ì „ì²´ í”Œë¡œìš° ì‹œí€€ìŠ¤

```mermaid
sequenceDiagram
    participant Client as webOS Client
    participant Camera as Luna Camera API
    participant Backend as Express Backend
    participant FaceAPI as Face Recognition
    participant DB as PostgreSQL

    Client->>Camera: installModel("FACE")
    Client->>Camera: getCameraList()
    Camera-->>Client: cameraId
    Client->>Camera: setPermission()
    Client->>Camera: open(cameraId)
    Camera-->>Client: handle
    Client->>Camera: setFormat(handle)
    Client->>Camera: startPreview(handle)
    Client->>Camera: takePicture(handle)
    Camera-->>Client: imageData

    Client->>Backend: POST /auth/face-login (image)
    Backend->>FaceAPI: extractFaceDescriptor(image)
    FaceAPI-->>Backend: descriptor
    Backend->>DB: SELECT all users
    DB-->>Backend: users[]
    Backend->>FaceAPI: compareFaces(descriptor, stored)
    FaceAPI-->>Backend: similarity
    Backend->>Backend: JWT.sign()
    Backend-->>Client: { token, userId, username }

    Client->>Client: saveToken(token)
    Client->>Client: navigate('/home')
```

---

## 5. í…ŒìŠ¤íŠ¸ ë°©ë²•

### 5-1. ì–¼êµ´ ë“±ë¡ (ê°œë°œìš©)

```bash
curl -X POST http://localhost:8080/auth/register-face \
  -F "image=@test_face.jpg" \
  -F "username=í™ê¸¸ë™"
```

### 5-2. ì–¼êµ´ ë¡œê·¸ì¸

```bash
curl -X POST http://localhost:8080/auth/face-login \
  -F "image=@test_face.jpg"
```

---

## 6. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **HTTPS í•„ìˆ˜**: í”„ë¡œë•ì…˜ì—ì„œëŠ” ë°˜ë“œì‹œ HTTPS ì‚¬ìš©
2. **ì´ë¯¸ì§€ í¬ê¸° ì œí•œ**: í˜„ì¬ 10MB (MAX_FILE_SIZE)
3. **Rate Limiting**: ë¬´ì°¨ë³„ ëŒ€ì… ê³µê²© ë°©ì§€
4. **ì–¼êµ´ ìœ ì‚¬ë„ ì„ê³„ê°’**: 0.6 (ì¡°ì • ê°€ëŠ¥)
5. **JWT ë§Œë£Œ ì‹œê°„**: 24ì‹œê°„ (env.JWT_EXPIRES_IN)

---

## 7. ì„±ëŠ¥ ìµœì í™”

1. **ìºì‹±**: ì–¼êµ´ ë””ìŠ¤í¬ë¦½í„°ë¥¼ ë©”ëª¨ë¦¬ì— ìºì‹±
2. **ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•**: webOSì—ì„œ 640x480ìœ¼ë¡œ ì „ì†¡
3. **ë¹„ë™ê¸° ì²˜ë¦¬**: ì–¼êµ´ ë¹„êµë¥¼ ë³‘ë ¬ ì²˜ë¦¬
4. **ì¸ë±ì‹±**: PostgreSQLì— ì‚¬ìš©ì ID ì¸ë±ìŠ¤

---

## 8. ì—ëŸ¬ ì²˜ë¦¬

| ì—ëŸ¬ ì½”ë“œ | ë©”ì‹œì§€                           | í•´ê²° ë°©ë²•        |
| --------- | -------------------------------- | ---------------- |
| 400       | ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤         | íŒŒì¼ ì—…ë¡œë“œ í™•ì¸ |
| 401       | ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤        | ì¡°ëª…/ê°ë„ ì¡°ì •   |
| 401       | ë“±ë¡ëœ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ | ì–¼êµ´ ì¬ë“±ë¡ í•„ìš” |
| 500       | ì„œë²„ ì˜¤ë¥˜                        | ë¡œê·¸ í™•ì¸        |

---

ì´ì œ webOS í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì¹´ë©”ë¼ë¡œ ì–¼êµ´ì„ ì´¬ì˜í•˜ê³ , ë°±ì—”ë“œì—ì„œ Face Recognitionìœ¼ë¡œ ì¸ì¦í•˜ëŠ” ì „ì²´ ì‹œìŠ¤í…œì´ ì™„ì„±ë©ë‹ˆë‹¤! ğŸ‰
